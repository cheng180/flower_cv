import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
from utils import save_checkpoint, plot_confusion_matrix, save_training_report
from config import config
from torch.cuda.amp import GradScaler, autocast
from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR, ReduceLROnPlateau
import numpy as np
import time


class LabelSmoothingCrossEntropy(nn.Module):
    """æ ‡ç­¾å¹³æ»‘æŸå¤±å‡½æ•°"""

    def __init__(self, smoothing=0.1):
        super().__init__()
        self.smoothing = smoothing

    def forward(self, preds, target):
        # æ·»åŠ æ•°å€¼ç¨³å®šæ€§ä¿æŠ¤
        stable_preds = preds.clamp(min=-20.0, max=20.0)
        log_preds = torch.log_softmax(stable_preds, dim=-1)
        nll_loss = -log_preds.gather(dim=-1, index=target.unsqueeze(1))
        nll_loss = nll_loss.squeeze(1)
        smooth_loss = -log_preds.mean(dim=-1)
        loss = (1.0 - self.smoothing) * nll_loss + self.smoothing * smooth_loss
        return loss.mean()


def train_model(model, train_loader, val_loader, device):
    # é€‰æ‹©æŸå¤±å‡½æ•° - å¸¦æ ‡ç­¾å¹³æ»‘
    if config.label_smoothing > 0:
        criterion = LabelSmoothingCrossEntropy(smoothing=config.label_smoothing)
    else:
        # æ·»åŠ ç¨³å®šæ€§ä¿æŠ¤çš„äº¤å‰ç†µæŸå¤±
        criterion = nn.CrossEntropyLoss()

    # AdamWä¼˜åŒ–å™¨æ·»åŠ æƒé‡è¡°å‡
    optimizer = optim.AdamW(
        model.parameters(),
        lr=config.lr,
        weight_decay=config.weight_decay
    )

    # å­¦ä¹ çŽ‡è°ƒåº¦å™¨
    if config.lr_schedule == 'cosine':
        scheduler = CosineAnnealingLR(optimizer, config.epochs, eta_min=config.min_lr)
    elif config.lr_schedule == 'step':
        scheduler = StepLR(optimizer, step_size=config.lr_step_size, gamma=config.lr_gamma)
    else:
        scheduler = ReduceLROnPlateau(optimizer, patience=3, factor=0.5, verbose=True)

    # æ··åˆç²¾åº¦è®­ç»ƒ
    scaler = GradScaler(enabled=config.use_amp)

    best_acc = 0.0
    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}

    print(f"âš™ï¸  è®­ç»ƒé…ç½®: AMP={config.use_amp}, æ ‡ç­¾å¹³æ»‘={config.label_smoothing}, æƒé‡è¡°å‡={config.weight_decay}")
    print(f"âš™ï¸  å­¦ä¹ çŽ‡è°ƒåº¦: {config.lr_schedule}, epochs={config.epochs}")

    for epoch in range(config.epochs):
        epoch_start = time.time()

        # è®­ç»ƒé˜¶æ®µ
        model.train()
        running_loss, correct, total = 0.0, 0, 0

        for images, labels in tqdm(train_loader, desc=f"Epoch {epoch + 1}/{config.epochs}"):
            if images.nelement() == 0 or labels.nelement() == 0:
                continue

            images, labels = images.to(device), labels.to(device)

            # æ··åˆç²¾åº¦è®­ç»ƒ
            with autocast(enabled=config.use_amp):
                optimizer.zero_grad()
                outputs = model(images)

                # æ·»åŠ è¾“å‡ºç¨³å®šæ€§ä¿æŠ¤
                outputs = outputs.clamp(min=-20.0, max=20.0)

                loss = criterion(outputs, labels)

            # åå‘ä¼ æ’­
            scaler.scale(loss).backward()

            # æ¢¯åº¦è£å‰ª
            if config.clip_grad > 0:
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(model.parameters(), config.clip_grad)

            scaler.step(optimizer)
            scaler.update()

            # ç»Ÿè®¡ä¿¡æ¯
            running_loss += loss.item() * images.size(0)
            _, preds = outputs.max(1)
            total += labels.size(0)
            correct += preds.eq(labels).sum().item()

        # è®¡ç®—è®­ç»ƒæŒ‡æ ‡
        train_loss = running_loss / total if total > 0 else 0.0
        train_acc = 100. * correct / total

        # éªŒè¯é˜¶æ®µ
        val_loss, val_acc, all_preds, all_labels = evaluate(model, val_loader, criterion, device)

        # æ›´æ–°å­¦ä¹ çŽ‡è°ƒåº¦å™¨
        if isinstance(scheduler, ReduceLROnPlateau):
            scheduler.step(val_loss)
        else:
            scheduler.step()

        # è®°å½•åŽ†å²
        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['train_acc'].append(train_acc)
        history['val_acc'].append(val_acc)

        # æ‰“å°è®­ç»ƒè¿›åº¦
        epoch_time = time.time() - epoch_start
        lr = optimizer.param_groups[0]['lr']
        print(f"Epoch [{epoch + 1}/{config.epochs}] | "
              f"Time: {epoch_time:.0f}s | LR: {lr:.6f} | "
              f"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | "
              f"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%")

        # ä¿å­˜æœ€ä½³æ¨¡åž‹
        if val_acc > best_acc:
            best_acc = val_acc
            save_checkpoint(model, optimizer, scheduler, epoch, best_acc)

            # ä¿å­˜æ··æ·†çŸ©é˜µ
            if config.plot_confusion_matrix and config.confusion_matrix_size and len(all_preds) > 0:
                cm = plot_confusion_matrix(all_labels, all_preds,
                                           title=f'Best Confusion Matrix @ Epoch {epoch + 1}',
                                           figsize=config.confusion_matrix_size)
                report = save_training_report(all_labels, all_preds, val_acc, config.classes)

    # è®­ç»ƒç»“æŸ
    print(f"\nðŸ† è®­ç»ƒå®Œæˆ! æœ€ä½³éªŒè¯å‡†ç¡®çŽ‡: {best_acc:.2f}%")
    print(f"âœ… å®Œæˆæ‰€æœ‰ {config.epochs} ä¸ª epoch çš„è®­ç»ƒ")
    return history


def evaluate(model, loader, criterion, device):
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for images, labels in loader:
            if images.nelement() == 0 or labels.nelement() == 0:
                continue

            images, labels = images.to(device), labels.to(device)

            # ä¸è®¡ç®—æ¢¯åº¦çš„å‰å‘ä¼ æ’­
            with autocast(enabled=config.use_amp):
                outputs = model(images)

                # æ·»åŠ è¾“å‡ºç¨³å®šæ€§ä¿æŠ¤
                outputs = outputs.clamp(min=-20.0, max=20.0)

                loss = criterion(outputs, labels)

            running_loss += loss.item() * images.size(0)
            _, preds = outputs.max(1)

            total += labels.size(0)
            correct += preds.eq(labels).sum().item()

            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # è®¡ç®—æŒ‡æ ‡
    val_loss = running_loss / total if total > 0 else 0.0
    val_acc = 100. * correct / total if total > 0 else 0.0

    return val_loss, val_acc, all_preds, all_labels
